{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=1.0, loss='deviance', max_depth=1,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "Estimated score GradientBoostingClassifier : 0.97881 (+/- 0.01148)\n",
      "                                                   URL  result\n",
      "0                                   http://087508.com/       1\n",
      "1                                  http://13.75.43.83/       1\n",
      "2           http://184.71.190.206:808/1/www.bn.com.pe/       1\n",
      "3                                 http://34.199.8.144/       1\n",
      "4                            http://34.228.2.136/1.php       1\n",
      "5    http://3iview.com/techno.php?q=legal-informati...       1\n",
      "6              http://6112-webtechpro.xyz/german-micro       1\n",
      "7    http://67.210.122.222/~deen/file%20/hs/Validat...       1\n",
      "8                                   http://6l9y.mjt.lu       0\n",
      "9                               http://82.165.229.138/       1\n",
      "10                               http://85.214.121.62/       1\n",
      "11   http://aabawaria.pl/docx/drop/newshared/files/...       1\n",
      "12        http://aardvarkresearchgroup.com/free-dd214/       1\n",
      "13   http://abgsites.com.br/clientes/ale/empresa.ph...       1\n",
      "14   http://account.signinupdate.support/webapps/38...       1\n",
      "15               http://aciadonotebook.com.br/contato/       1\n",
      "16   http://action-loginlink.action.scoran.com/What...       1\n",
      "17              http://adm692.at.ua/reconfirm_now.html       1\n",
      "18   http://agroeconom.kz/api/getn.php?id=amJsb29kc...       1\n",
      "19   http://alex-logistic.com.ua/amc/docusignOffice...       1\n",
      "20   http://alilaanji.cn/ink/ServiceL=ogin%253fserv...       1\n",
      "21           http://alkatheebinteriors.com/info/sites/       1\n",
      "22                http://alphagraphics.com.sa/graphics       1\n",
      "23                 http://amazingdealfx.com/Power/Win/       1\n",
      "24   http://amiba.ma/administrator/help/en-GB/css/i...       1\n",
      "25            http://ammanchamber.com.ng/ACC6/adbb/ad/       1\n",
      "26       http://ana-fashion.com/admin/css/s.p/jkh.html       1\n",
      "27   http://andahoho15.mystagingwebsite.com/wp-cont...       1\n",
      "28         http://anetteportfolio.com/wp-includes/pomo       1\n",
      "29   http://anime-srbija.ucoz.com/publ/anime_1/btoo...       1\n",
      "..                                                 ...     ...\n",
      "920                             http://milliyet.com.tr       0\n",
      "921                            http://minecraftevi.com       0\n",
      "922                           http://ministerial5.com/       0\n",
      "923                                     http://mlb.com       0\n",
      "924                                http://mobile01.com       0\n",
      "925                                http://mologiq.net/       0\n",
      "926                              http://money.cnn.com/       0\n",
      "927                            http://moneycontrol.com       0\n",
      "928                                 http://monster.com       0\n",
      "929                              http://motherless.com       0\n",
      "930                          http://moviescounter.com/       0\n",
      "931                               http://movieseum.com       0\n",
      "932                                     http://moz.com       0\n",
      "933                                 http://mozilla.org       0\n",
      "934                                     http://msn.com       0\n",
      "935                              http://myfreecams.com       0\n",
      "936                                http://mynet.com.tr       0\n",
      "937                             http://mywebsearch.com       0\n",
      "938                               http://namecheap.com       0\n",
      "939                                    http://narod.ru       0\n",
      "940                               http://naturalon.com       0\n",
      "941                                  http://naukri.com       0\n",
      "942                                   http://naver.com       0\n",
      "943                                    http://naver.jp       0\n",
      "944                                 http://nbcnews.com       0\n",
      "945                                    http://ndtv.com       0\n",
      "946                                  http://neobux.com       0\n",
      "947                                 http://netflix.com       0\n",
      "948                          http://nevonprojects.com/       0\n",
      "949                                  http://newegg.com       0\n",
      "\n",
      "[950 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#import Feature_extraction as urlfeature # this will take file feature_extraction as urlfeature\n",
    "import trainer as tr # this will take file train.py as tr\n",
    "def resultwriter(feature,output_dest): # this will write all the features iin a csv file\n",
    "    flag=True\n",
    "    with open(output_dest,'wb') as f:\n",
    "        for item in feature:\n",
    "            w = csv.DictWriter(f, item[1].keys())\n",
    "            if flag:\n",
    "                w.writeheader()\n",
    "                flag=False\n",
    "            w.writerow(item[1])\n",
    "\n",
    "def process_URL_list(file_dest,output_dest):# i think this takes whole file of urls with given malicious to extract their  feature and provide malicious column also like this will take url.txt\n",
    "    feature=[]\n",
    "    with open(file_dest) as file:\n",
    "        for line in file:\n",
    "            url=line.split(',')[0].strip()\n",
    "            malicious_bool=line.split(',')[1].strip()\n",
    "            if url!='':\n",
    "                print ('working on: '+url)           #showoff \n",
    "                ret_dict=urlfeature.feature_extract(url)\n",
    "                ret_dict['malicious']=malicious_bool\n",
    "                feature.append([url,ret_dict]);\n",
    "    resultwriter(feature,output_dest)\n",
    "\n",
    "def process_test_list(file_dest,output_dest):  # i think this takes whole file of urls without given malicious to extract their  feature and doest not provide malicious column like this will take query.txt\n",
    "    feature=[]\n",
    "    with open(file_dest) as file:\n",
    "        for line in file:\n",
    "            url=line.strip()\n",
    "            if url!='':\n",
    "                print ('working on: '+url)           #showoff \n",
    "                ret_dict=urlfeature.feature_extract(url)\n",
    "                feature.append([url,ret_dict]);\n",
    "    resultwriter(feature,output_dest)\n",
    "\n",
    "#change\n",
    "def process_test_url(url,output_dest): # i think this takes  a single url to extract feature, this is used in gui.py file only\n",
    "    feature=[]\n",
    "    url=url.strip()\n",
    "    if url!='':\n",
    "        print ('working on: '+url)           #showoff \n",
    "        ret_dict=urlfeature.feature_extract(url)\n",
    "        feature.append([url,ret_dict]);\n",
    "    resultwriter(feature,output_dest)\n",
    "\n",
    "\n",
    "def main():# i think 1,2,4 lines are appropriate to for creating extracted features file of train and test data then apply model on them\n",
    "        #process_URL_list('URL.txt','url_features.csv')\n",
    "        #process_test_list(\"query.txt\",'query_features.csv')\n",
    "        #tr.train('url_features.csv','url_features.csv')       #arguments:(input_training feature,test/query traning features)\n",
    "        tr.train('train_features_imp.csv','test_features_imp.csv')      #testing with urls in query.txt \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
